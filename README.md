# ğŸ›¡ï¸ VoiceShield â€” AI Deepfake Voice Detection

Real-time deepfake voice detection system powered by a **ResNet-style deep learning model** trained on log-mel spectrograms.

Detects AI-generated (fake) voices vs. real human speech with high confidence.

---

## ğŸš€ Quick Start

```bash
# 1. Clone
git clone https://github.com/YOUR_USERNAME/AIfakevoicesddetection.git
cd AIfakevoicesddetection

# 2. Install dependencies
pip install -r requirements.txt

# 3. Add your trained model
# Place best_model.keras inside: data/models/<run_name>/

# 4. Start the server
python run_server.py

# 5. Open the UI
# â†’ http://127.0.0.1:8000/ui
```

---

## ğŸ“ Project Structure

```
AIfakevoicesddetection/
â”œâ”€â”€ training/               â† Model + feature extraction + config
â”‚   â”œâ”€â”€ config.py           â† All hyperparameters (env-var overridable)
â”‚   â”œâ”€â”€ feature_extraction.py â† Log-mel spectrogram extraction
â”‚   â”œâ”€â”€ spec_augment.py     â† SpecAugment Keras layer
â”‚   â”œâ”€â”€ model.py            â† ResNet binary classifier
â”‚   â”œâ”€â”€ dataset.py          â† tf.data pipeline
â”‚   â”œâ”€â”€ metrics.py          â† AUC, EER, confusion matrix
â”‚   â”œâ”€â”€ train.py            â† Training orchestrator
â”‚   â””â”€â”€ resplit.py          â† Speaker-level stratified splitting
â”œâ”€â”€ frontend/               â† Professional web UI
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”œâ”€â”€ inference/              â† Ensemble prediction
â”‚   â””â”€â”€ ensemble_predict.py
â”œâ”€â”€ data/                   â† Dataset + models (gitignored)
â”‚   â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ run_server.py           â† FastAPI server
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example            â† Environment config template
â””â”€â”€ .gitignore
```

---

## ğŸ—ï¸ Architecture

| Component | Details |
|-----------|---------|
| **Features** | 80-bin log-mel spectrogram, 4s clips, per-sample normalized |
| **Augmentation** | SpecAugment (time + frequency masking) |
| **Model** | ResNet-style CNN: stem â†’ 3 residual stages (32/64/128) â†’ GAP â†’ Dense â†’ Sigmoid |
| **Training** | Binary cross-entropy + label smoothing, Adam optimizer, val AUC checkpointing |
| **Metrics** | AUC, EER, confusion matrix |
| **Backend** | FastAPI + uvicorn |
| **Frontend** | Vanilla HTML/CSS/JS, dark AI theme, drag-and-drop upload |

---

## ğŸ”§ Configuration

All paths are configurable via environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `VOICESHIELD_DATASET` | `data/dataset` | Dataset root |
| `VOICESHIELD_MODELS` | `data/models` | Model output directory |
| `VOICESHIELD_LOGS` | `data/logs` | TensorBoard logs |
| `VOICESHIELD_MODEL_PATH` | Auto-discovered | Direct path to `.keras` model |
| `VOICESHIELD_UPLOADS` | `data/uploads` | Temp upload directory |

Copy `.env.example` to `.env` and modify as needed.

---

## ğŸ“¡ API

### `POST /predict`

Upload an audio file â†’ get prediction.

```bash
curl -X POST http://localhost:8000/predict -F "file=@audio.wav"
```

**Response:**
```json
{
  "label": "FAKE",
  "confidence": 0.9787
}
```

### `GET /ui`
Web interface for drag-and-drop detection.

### `GET /docs`
Interactive Swagger API documentation.

---

## ğŸ§ª Ensemble Prediction (CLI)

```bash
python -m inference.ensemble_predict "path/to/audio.wav"
```

Combines `best_model.keras` + `final_model.keras` via probability averaging.

---

## ğŸ“Š Training

```bash
# Retrain the model
python -m training.train
```

Requires dataset in `data/dataset/` with `metadata_clean.csv`.

---

## ğŸ“¦ Requirements

- Python 3.10+
- TensorFlow / Keras
- Librosa
- FastAPI + uvicorn
- NumPy, Pandas, scikit-learn

---

## ğŸ“ License

MIT

---

**Built with â¤ï¸ by VoiceShield AI**
